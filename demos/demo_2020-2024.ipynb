{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snowpylot demo for Western Snow Conference 2025\n",
    "Demonstrating the functionality of the snowpylot library using snowpits from the 2020-2024 water years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "import plotly.express as px\n",
    "from snowpylot.caaml_parser import caaml_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pits(folder_path):\n",
    "    \"\"\"\n",
    "    Function to parse CAAML files in the specified folder\n",
    "    \"\"\"\n",
    "\n",
    "    files = [\n",
    "        f for f in os.listdir(folder_path) if f.endswith(\".xml\")\n",
    "    ]  # List of all .xml files in the folder\n",
    "\n",
    "    pits_list = []\n",
    "\n",
    "    for file in files:  # iterate through each file in the folder\n",
    "        file_path = folder_path + \"/\" + file  # create the file path\n",
    "        pit = caaml_parser(file_path)  # parse the file\n",
    "        pits_list.append(pit)\n",
    "\n",
    "    return pits_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Layer' object has no attribute 'layerOfConcern'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define folders and parse pits\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m pits_19_20 \u001b[38;5;241m=\u001b[39m \u001b[43mparse_pits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msnowpits/by_season/2019-2020\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m pits_20_21 \u001b[38;5;241m=\u001b[39m parse_pits(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnowpits/by_season/2020-2021\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m pits_21_22 \u001b[38;5;241m=\u001b[39m parse_pits(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnowpits/by_season/2021-2022\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m, in \u001b[0;36mparse_pits\u001b[1;34m(folder_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:  \u001b[38;5;66;03m# iterate through each file in the folder\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m folder_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m file  \u001b[38;5;66;03m# create the file path\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     pit \u001b[38;5;241m=\u001b[39m \u001b[43mcaaml_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# parse the file\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     pits_list\u001b[38;5;241m.\u001b[39mappend(pit)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pits_list\n",
      "File \u001b[1;32m~\\Desktop\\SnowPilot Repo\\SnowPilotAnalytics\\src\\snowpylot\\caaml_parser.py:230\u001b[0m, in \u001b[0;36mcaaml_parser\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m layer\u001b[38;5;241m.\u001b[39miter(caaml_tag \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    228\u001b[0m             layer_obj\u001b[38;5;241m.\u001b[39mset_comments(prop\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m--> 230\u001b[0m         \u001b[43mpit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msnowProfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m## tempProfile\u001b[39;00m\n\u001b[0;32m    233\u001b[0m tempProfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(root\u001b[38;5;241m.\u001b[39miter(caaml_tag \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtempProfile\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Desktop\\SnowPilot Repo\\SnowPilotAnalytics\\src\\snowpylot\\snowProfile.py:245\u001b[0m, in \u001b[0;36mSnowProfile.add_layer\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03mAdd a layer to the snow profile.\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \n\u001b[0;32m    241\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    layer: The layer to add\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mappend(layer)\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayerOfConcern\u001b[49m:\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_of_concern \u001b[38;5;241m=\u001b[39m layer\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Layer' object has no attribute 'layerOfConcern'"
     ]
    }
   ],
   "source": [
    "# Define folders and parse pits\n",
    "\n",
    "pits_19_20 = parse_pits(\"snowpits/by_season/2019-2020\")\n",
    "pits_20_21 = parse_pits(\"snowpits/by_season/2020-2021\")\n",
    "pits_21_22 = parse_pits(\"snowpits/by_season/2021-2022\")\n",
    "pits_22_23 = parse_pits(\"snowpits/by_season/2022-2023\")\n",
    "pits_23_24 = parse_pits(\"snowpits/by_season/2023-2024\")\n",
    "\n",
    "all_pits = (\n",
    "    pits_19_20 + pits_20_21 + pits_21_22 + pits_22_23 + pits_23_24\n",
    ")  # list of all pits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create DataFrame of Core Info for all Pits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_info_list = []\n",
    "\n",
    "for pit in all_pits:\n",
    "    core_info_dict = {\n",
    "        # metadata\n",
    "        \"PitID\": pit.coreInfo.pitID,\n",
    "        \"Date\": pit.coreInfo.date,\n",
    "        # User\n",
    "        \"SnowPilot Username\": pit.coreInfo.user.username,\n",
    "        \"Professional\": pit.coreInfo.user.professional,\n",
    "        \"Operation Name\": pit.coreInfo.user.operationName,\n",
    "        # Location\n",
    "        \"Latitude\": pit.coreInfo.location.latitude,\n",
    "        \"Longitude\": pit.coreInfo.location.longitude,\n",
    "        \"Elevation\": pit.coreInfo.location.elevation,\n",
    "        \"Aspect\": pit.coreInfo.location.aspect,\n",
    "        \"Slope Angle\": pit.coreInfo.location.slopeAngle,\n",
    "        \"Country\": pit.coreInfo.location.country,\n",
    "        \"Region\": pit.coreInfo.location.region,\n",
    "        \"Pit Near Avalanche\": pit.coreInfo.location.pitNearAvalanche,\n",
    "        \"Pit Near Avalanche Location\": pit.coreInfo.location.pitNearAvalancheLocation,\n",
    "    }\n",
    "    core_info_list.append(core_info_dict)\n",
    "\n",
    "core_info_df = pd.DataFrame(core_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update country and region for pits with \"UT\" as country\n",
    "mask = core_info_df[\"Country\"] == \"UT\"\n",
    "core_info_df.loc[mask, \"Country\"] = \"US\"\n",
    "core_info_df.loc[mask, \"Region\"] = \"UT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Summary Tables of Core Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table of core_info_df\n",
    "core_info_summary = {\n",
    "    \"Total Pits\": len(core_info_df),  # Total quantity of PitID\n",
    "    \"Unique Users\": core_info_df[\"SnowPilot Username\"].nunique(),  # Unique Usernames\n",
    "    \"Professional Pits\": core_info_df[\n",
    "        \"Professional\"\n",
    "    ].sum(),  # Count of Professional = True\n",
    "    \"Non-professional Pits\": (\n",
    "        ~core_info_df[\"Professional\"]\n",
    "    ).sum(),  # Count of Professional = False\n",
    "    \"Operation with the Most Pits\": core_info_df[\"Operation Name\"]\n",
    "    .value_counts()\n",
    "    .index[0],\n",
    "    \"Number of Pits Submitted by the CIAC\": core_info_df[\"Operation Name\"]\n",
    "    .value_counts()\n",
    "    .iloc[0],\n",
    "}\n",
    "\n",
    "print(\"Summary of Pit MetaData:\")\n",
    "for key, value in core_info_summary.items():\n",
    "    print(key + \":\" + str(value))\n",
    "\n",
    "location_info_summary = {\n",
    "    \"Unique Countries\": core_info_df[\"Country\"].nunique(),  # Unique Countries\n",
    "    \"Pits Near an Avalanche\": core_info_df[\n",
    "        \"Pit Near Avalanche\"\n",
    "    ].sum(),  # Count of Pit Near Avalanche = True\n",
    "    \"Pits on Avalanche Crown\": core_info_df[\n",
    "        core_info_df[\"Pit Near Avalanche Location\"] == \"crown\"\n",
    "    ].shape[0],\n",
    "    \"Pits on Avalanche Flank\": core_info_df[\n",
    "        core_info_df[\"Pit Near Avalanche Location\"] == \"flank\"\n",
    "    ].shape[0],\n",
    "}\n",
    "\n",
    "print(\"\\nSummary of Location Info:\")\n",
    "for key, value in location_info_summary.items():\n",
    "    print(key + \":\" + str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pie Chart of Qty Of Snow Pits by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pie chart of snow pits by country\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Get the count of pits by country\n",
    "country_counts = core_info_df[\"Country\"].value_counts()\n",
    "\n",
    "# Calculate percentages\n",
    "total_pits = country_counts.sum()\n",
    "percentages = (country_counts / total_pits) * 100\n",
    "\n",
    "# Create lists for labels and values, only including labels for >2%\n",
    "labels = []\n",
    "values = []\n",
    "for country, count in country_counts.items():\n",
    "    percentage = (count / total_pits) * 100\n",
    "    if percentage > 2:\n",
    "        labels.append(country)\n",
    "    else:\n",
    "        labels.append(\"\")  # Empty label for small slices\n",
    "    values.append(count)\n",
    "\n",
    "\n",
    "# Create a function to format the percentage labels\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        # Only show percentage if it's greater than 2%\n",
    "        if pct > 2:\n",
    "            return f\"{pct:.1f}%\"\n",
    "        return \"\"\n",
    "\n",
    "    return my_autopct\n",
    "\n",
    "\n",
    "# Create the pie chart\n",
    "plt.pie(values, labels=labels, autopct=make_autopct(values))\n",
    "\n",
    "# Add a title\n",
    "plt.title(\"Distribution of Snow Pits by Country\")\n",
    "\n",
    "# Add a legend with country codes and counts (including all countries)\n",
    "plt.legend(\n",
    "    [\n",
    "        f\"{country} ({count})\"\n",
    "        for country, count in zip(country_counts.index, country_counts.values)\n",
    "    ],\n",
    "    title=\"Countries\",\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    ")\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Heatmap of Snow Pit Locations in the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for US locations only and remove any rows with missing coordinates\n",
    "us_pits = core_info_df[\n",
    "    (core_info_df[\"Country\"] == \"US\")\n",
    "    & (core_info_df[\"Latitude\"].notna())\n",
    "    & (core_info_df[\"Longitude\"].notna())\n",
    "].copy()\n",
    "\n",
    "# Create a list of locations for the heatmap\n",
    "locations = us_pits[[\"Latitude\", \"Longitude\"]].values.tolist()\n",
    "\n",
    "# Create a base map centered on the US\n",
    "m = folium.Map(location=[39.8283, -98.5795], zoom_start=4)\n",
    "\n",
    "# Add the heatmap layer\n",
    "HeatMap(locations).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snow Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataframe Of SnowProfile Info for All Pits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_profile_list = []\n",
    "\n",
    "for pit in all_pits:\n",
    "    numPrimaryGrainForm = 0  # initialize\n",
    "    numPrimaryGrainSize = 0  # initialize\n",
    "    for layer in pit.snowProfile.layers:  # iterate through each layer in the pit\n",
    "        if layer.grainFormPrimary is not None:  # if the layer has a primary grain form\n",
    "            numPrimaryGrainForm += 1  # increment the number of primary grain forms\n",
    "            if (\n",
    "                layer.grainFormPrimary.grainSizeAvg is not None\n",
    "            ):  # if the layer has a primary grain size\n",
    "                numPrimaryGrainSize += 1  # increment the number of primary grain sizes\n",
    "\n",
    "    snow_profile_dict = {\n",
    "        \"PitID\": pit.coreInfo.pitID,\n",
    "        \"Measurement Direction\": pit.snowProfile.measurementDirection,\n",
    "        \"Profile Depth\": pit.snowProfile.profileDepth,\n",
    "        \"HS\": pit.snowProfile.hS,\n",
    "        # Surface Conditions\n",
    "        \"Foot Penetration\": pit.snowProfile.surfCond.penetrationFoot,\n",
    "        \"Ski Penetration\": pit.snowProfile.surfCond.penetrationSki,\n",
    "        # Layers\n",
    "        \"Num Layers\": len(pit.snowProfile.layers),\n",
    "        \"num Layers wPrimary Grain Form\": numPrimaryGrainForm,\n",
    "        \"num Layers wPrimary Grain Size\": numPrimaryGrainSize,\n",
    "        # Temp Profile\n",
    "        \"Temp Profile\": True if pit.snowProfile.tempProfile is not None else False,\n",
    "        \"Num Temp Obs\": len(pit.snowProfile.tempProfile)\n",
    "        if pit.snowProfile.tempProfile is not None\n",
    "        else 0,\n",
    "        # Density Profile\n",
    "        \"Density Profile\": True\n",
    "        if pit.snowProfile.densityProfile is not None\n",
    "        else False,\n",
    "        \"Num Density Obs\": len(pit.snowProfile.densityProfile)\n",
    "        if pit.snowProfile.densityProfile is not None\n",
    "        else 0,\n",
    "    }\n",
    "    snow_profile_list.append(snow_profile_dict)\n",
    "\n",
    "snow_profile_df = pd.DataFrame(snow_profile_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Summary Tables of Snow Profile Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_profile_summary = {\n",
    "    \"Total Pits\": len(snow_profile_df),\n",
    "    \"Number of Layers\": snow_profile_df[\"Num Layers\"].sum(),\n",
    "    \"Number of Layers with Primary Grain Form\": snow_profile_df[\n",
    "        \"num Layers wPrimary Grain Form\"\n",
    "    ].sum(),\n",
    "    \"Number of Layers with Primary Grain Size\": snow_profile_df[\n",
    "        \"num Layers wPrimary Grain Size\"\n",
    "    ].sum(),\n",
    "    \"Number of Pits with Temperature Profile\": snow_profile_df[\"Temp Profile\"].sum(),\n",
    "    \"Number of Temperature Observations\": snow_profile_df[\"Num Temp Obs\"].sum(),\n",
    "    \"Number of Pits with Density Profile\": snow_profile_df[\"Density Profile\"].sum(),\n",
    "    \"Number of Density Observations\": snow_profile_df[\"Num Density Obs\"].sum(),\n",
    "    \"Number of Pits with Foot Penetration\": snow_profile_df[\"Foot Penetration\"]\n",
    "    .notna()\n",
    "    .sum(),  # Changed to count non-null values\n",
    "    \"Number of Pits with Ski Penetration\": snow_profile_df[\"Ski Penetration\"]\n",
    "    .notna()\n",
    "    .sum(),  # Changed to count non-null values\n",
    "}\n",
    "\n",
    "print(\"Summary of Snow Profile Info:\")\n",
    "for key, value in snow_profile_summary.items():\n",
    "    print(key + \":\" + str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataframe of Stability Test Info for All Pits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_tests_list = []\n",
    "\n",
    "for pit in all_pits:\n",
    "    stability_tests_dict = {\n",
    "        # metadata\n",
    "        \"PitID\": pit.coreInfo.pitID,\n",
    "        \"Num ECT\": len(pit.stabilityTests.ECT),\n",
    "        \"Num CT\": len(pit.stabilityTests.CT),\n",
    "        \"Num RBlock\": len(pit.stabilityTests.RBlock),\n",
    "        \"Num PST\": len(pit.stabilityTests.PST),\n",
    "    }\n",
    "    stability_tests_list.append(stability_tests_dict)\n",
    "\n",
    "stability_tests_df = pd.DataFrame(stability_tests_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Stability Test Info\n",
    "\n",
    "# Totals\n",
    "total_pits = len(stability_tests_df)\n",
    "total_w_stab_results = stability_tests_df[\n",
    "    (stability_tests_df[\"Num ECT\"] > 0)\n",
    "    | (stability_tests_df[\"Num CT\"] > 0)\n",
    "    | (stability_tests_df[\"Num PST\"] > 0)\n",
    "    | (stability_tests_df[\"Num RBlock\"] > 0)\n",
    "].shape[0]\n",
    "percent_w_stab_results = total_w_stab_results / total_pits\n",
    "\n",
    "stability_tests_summary = {\n",
    "    \"Total Pits\": total_pits,\n",
    "    \"Total Pits with Stability Test Results\": total_w_stab_results,\n",
    "    \"Percentage of Pits with Stability Test Results\": \"%.2f%%\"\n",
    "    % (percent_w_stab_results * 100),\n",
    "}\n",
    "\n",
    "print(\"Summary of Overall Available Test Info\")\n",
    "for key, value in stability_tests_summary.items():\n",
    "    print(key + \":\" + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Specific Test Info\n",
    "specific_test_info = {\n",
    "    # ECT\n",
    "    \"Total Pits with ECT Results\": (stability_tests_df[\"Num ECT\"] > 0).sum(),\n",
    "    \"Total ECT Results\": stability_tests_df[\"Num ECT\"].sum(),\n",
    "    \"Percentage of Pits with ECT Results\": \"%.2f%%\"\n",
    "    % ((((stability_tests_df[\"Num ECT\"] > 0).sum()) / total_pits) * 100),\n",
    "    # CT\n",
    "    \"Total Pits with CT Results\": (stability_tests_df[\"Num CT\"] > 0).sum(),\n",
    "    \"Total CT Results\": stability_tests_df[\"Num CT\"].sum(),\n",
    "    \"Percentage of Pits with CT Results\": \"%.2f%%\"\n",
    "    % ((((stability_tests_df[\"Num CT\"] > 0).sum()) / total_pits) * 100),\n",
    "    # PST\n",
    "    \"Total Pits with PST Results\": (stability_tests_df[\"Num PST\"] > 0).sum(),\n",
    "    \"Total PST Results\": stability_tests_df[\"Num PST\"].sum(),\n",
    "    \"Percentage of Pits with PST Results\": \"%.2f%%\"\n",
    "    % ((((stability_tests_df[\"Num PST\"] > 0).sum()) / total_pits) * 100),\n",
    "    # RBlock\n",
    "    \"Total Pits with RBlock Results\": (stability_tests_df[\"Num RBlock\"] > 0).sum(),\n",
    "    \"Total RBlock Results\": stability_tests_df[\"Num RBlock\"].sum(),\n",
    "    \"Percentage of Pits with RBlock Results\": \"%.2f%%\"\n",
    "    % ((((stability_tests_df[\"Num RBlock\"] > 0).sum()) / total_pits) * 100),\n",
    "}\n",
    "\n",
    "for key, value in specific_test_info.items():\n",
    "    print(key + \":\" + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total number of each test type and reorder to put RBlock last\n",
    "test_counts = {\n",
    "    \"ECT\": stability_tests_df[\"Num ECT\"].sum(),\n",
    "    \"CT\": stability_tests_df[\"Num CT\"].sum(),\n",
    "    \"PST\": stability_tests_df[\"Num PST\"].sum(),\n",
    "    \"RBlock\": stability_tests_df[\"Num RBlock\"].sum(),\n",
    "}\n",
    "# Calculate percentages\n",
    "total_tests = sum(test_counts.values())\n",
    "percentages = {k: (v / total_tests) * 100 for k, v in test_counts.items()}\n",
    "\n",
    "# Create simple labels for pie chart\n",
    "pie_labels = list(test_counts.keys())\n",
    "\n",
    "# Create detailed labels with percentages for legend\n",
    "legend_labels = [f\"{k} ({v:.1f}%)\" for k, v in percentages.items()]\n",
    "\n",
    "# Create pie chart\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.pie(test_counts.values(), labels=pie_labels, startangle=90)\n",
    "plt.title(\n",
    "    \"Distribution of Stability Test Types\", pad=20\n",
    ")  # Added padding to move title up\n",
    "plt.axis(\"equal\")  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(\n",
    "    legend_labels, title=\"Test Types\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1)\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primary Grain Class vs Hand Hardness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RQ2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Research Question 2**\n",
    "\n",
    "How often is a Q1 fracture associated with an ECTP on the same layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "\n",
    "CT_ECT_list = []\n",
    "\n",
    "for pit in all_pits:\n",
    "    # If the pit has CT and ECT results\n",
    "    if len(pit.stabilityTests.CT) > 0 and len(pit.stabilityTests.ECT) > 0:\n",
    "        ECTs = pit.stabilityTests.ECT  # Get ECT results\n",
    "        CTs = pit.stabilityTests.CT  # Get CT results\n",
    "\n",
    "        for ect in ECTs:\n",
    "            for ct in CTs:  # For Every combination of ECT and CT results\n",
    "                if (\n",
    "                    ect.depthTop == ct.depthTop and ect.propogation is True\n",
    "                ):  # If failure on the same level and ECT has propogation\n",
    "                    results_dict = {\n",
    "                        \"PitID\": pit.coreInfo.pitID,\n",
    "                        \"ECT Score\": ect.testScore,\n",
    "                        \"CT Shear Qual\": ct.fractureCharacter,\n",
    "                    }\n",
    "                    CT_ECT_list.append(results_dict)\n",
    "\n",
    "CT_ECT_df = pd.DataFrame(CT_ECT_list)\n",
    "# grouped = df.groupby(\"PitID\")\n",
    "# print(grouped.sum())\n",
    "\n",
    "# df = df.drop_duplicates(\n",
    "#    subset=[\"PitID\"], keep=\"first\"\n",
    "# )  # Drop duplicates per pit NOTE This keeps the first occurance, update?\n",
    "\n",
    "print(len(CT_ECT_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Fracture Character to Shear Quality\n",
    "\n",
    "fracture_to_shear_qual = {\n",
    "    \"Q1\": \"Q1\",\n",
    "    \"Q2\": \"Q2\",\n",
    "    \"Q3\": \"Q3\",\n",
    "    \"SC\": \"Q1\",\n",
    "    \"SP\": \"Q1\",\n",
    "    \"RP\": \"Q2\",\n",
    "    \"BRK\": \"Q3\",\n",
    "    \"PC\": \"Q2\",\n",
    "}\n",
    "\n",
    "# Add the new column using the mapping\n",
    "CT_ECT_df[\"Shear Qual\"] = CT_ECT_df[\"CT Shear Qual\"].map(fracture_to_shear_qual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pie Chart\n",
    "\n",
    "# Calculate value counts for ShearQual\n",
    "shear_counts = CT_ECT_df[\"CT Shear Qual\"].value_counts()\n",
    "\n",
    "# Create pie chart\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.pie(\n",
    "    shear_counts.values,\n",
    "    labels=shear_counts.index,\n",
    "    autopct=\"%1.1f%%\",  # Show percentages with 1 decimal place\n",
    "    startangle=90,\n",
    ")  # Rotate start of pie to 90 degrees\n",
    "\n",
    "# Add title\n",
    "plt.title(\n",
    "    \"Distribution of CT Shear Quality Results in Pits Where ECTP Occurs on the same Layer\",\n",
    "    pad=20,\n",
    ")\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.axis(\"equal\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treemap grouped by Mapped Shear Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with missing values\n",
    "CT_ECT_df_clean = CT_ECT_df.dropna(subset=[\"CT Shear Qual\", \"Shear Qual\"])\n",
    "\n",
    "# Create the treemap\n",
    "fig = px.treemap(\n",
    "    CT_ECT_df_clean,\n",
    "    path=[\"Shear Qual\", \"CT Shear Qual\"],\n",
    "    title=\"Distribution of CT Shear Quality Results\",\n",
    "    width=1000,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(\n",
    "    font_size=14,\n",
    "    title_font_size=16,\n",
    "    title_x=0.5,  # Center the title\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grain Type by hand Hardness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_info_list = []\n",
    "\n",
    "for pit in all_pits:\n",
    "    for layer in pit.snowProfile.layers:\n",
    "        # Get the grain form name safely, defaulting to None if grainFormPrimary is None\n",
    "        grain_form_name = (\n",
    "            layer.grainFormPrimary.basicGrainClass_name\n",
    "            if layer.grainFormPrimary\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        layer_info = {\n",
    "            \"Thickness\": layer.thickness,\n",
    "            \"Hand Hardness\": layer.hardness,\n",
    "            \"Layer of Concern\": layer.layerOfConcern,\n",
    "            \"Primary Grain Form Name\": grain_form_name,\n",
    "        }\n",
    "        layer_info_list.append(layer_info)\n",
    "\n",
    "layer_info_df = pd.DataFrame(layer_info_list)\n",
    "\n",
    "print(layer_info_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the order of Hand Hardness levels\n",
    "hardness_order = [\n",
    "    \"F-\",\n",
    "    \"F\",\n",
    "    \"F+\",\n",
    "    \"-4F\",\n",
    "    \"4F\",\n",
    "    \"4F+\",\n",
    "    \"1F-\",\n",
    "    \"1F\",\n",
    "    \"1F+\",\n",
    "    \"P-\",\n",
    "    \"P\",\n",
    "    \"P+\",\n",
    "    \"K-\",\n",
    "    \"K\",\n",
    "    \"K+\",\n",
    "    \"I-\",\n",
    "    \"I\",\n",
    "    \"I+\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Violin Plot\n",
    "\n",
    "# Function to wrap text\n",
    "def wrap_labels(ax, width=20):\n",
    "    ticks = ax.get_xticks()\n",
    "    labels = [\n",
    "        textwrap.fill(label.get_text(), width=width) for label in ax.get_xticklabels()\n",
    "    ]\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(labels)\n",
    "\n",
    "\n",
    "# Violin Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(x=\"Primary Grain Form Name\", y=\"Hand Hardness\", data=layer_info_df)\n",
    "plt.title(\"Distribution of Hand Hardness by Primary Grain Form\")\n",
    "plt.xlabel(\"Primary Grain Form\")\n",
    "plt.ylabel(\"Hand Hardness\")\n",
    "wrap_labels(plt.gca(), width=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation of Hand Hardness and Primary Grain Form Name\n",
    "heatmap_data = pd.crosstab(\n",
    "    layer_info_df[\"Primary Grain Form Name\"], layer_info_df[\"Hand Hardness\"]\n",
    ")\n",
    "\n",
    "# Reorder the columns according to the specified order\n",
    "# Only include columns that exist in the data\n",
    "existing_columns = [col for col in hardness_order if col in heatmap_data.columns]\n",
    "heatmap_data = heatmap_data[existing_columns]\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(\n",
    "    heatmap_data,\n",
    "    annot=True,  # Show numbers in cells\n",
    "    fmt=\"d\",  # Format as integers\n",
    "    cmap=\"YlOrRd\",  # Yellow to Orange to Red color scheme\n",
    "    cbar_kws={\"label\": \"Count\"},\n",
    ")\n",
    "\n",
    "plt.title(\"Heatmap of Hand Hardness by Primary Grain Form\")\n",
    "plt.xlabel(\"Hand Hardness\")\n",
    "plt.ylabel(\"Primary Grain Form\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Hardness to group\n",
    "\n",
    "hardness_to_group = {\n",
    "    \"F-\": \"F\",\n",
    "    \"F\": \"F\",\n",
    "    \"F+\": \"F\",\n",
    "    \"-4F\": \"4F\",\n",
    "    \"4F\": \"4F\",\n",
    "    \"4F+\": \"4F\",\n",
    "    \"1F-\": \"1F\",\n",
    "    \"1F\": \"1F\",\n",
    "    \"1F+\": \"1F\",\n",
    "    \"P-\": \"P\",\n",
    "    \"P\": \"P\",\n",
    "    \"P+\": \"P\",\n",
    "    \"K-\": \"K\",\n",
    "    \"K\": \"K\",\n",
    "    \"K+\": \"K\",\n",
    "    \"I-\": \"I\",\n",
    "    \"I\": \"I\",\n",
    "    \"I+\": \"I\",\n",
    "}\n",
    "\n",
    "# Add the new column using the mapping\n",
    "layer_info_df[\"Hardness Group\"] = layer_info_df[\"Hand Hardness\"].map(hardness_to_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation of Hand Hardness Group and Primary Grain Form Name\n",
    "heatmap_data = pd.crosstab(\n",
    "    layer_info_df[\"Primary Grain Form Name\"], layer_info_df[\"Hardness Group\"]\n",
    ")\n",
    "\n",
    "# Reorder the columns according to the specified order\n",
    "# Only include columns that exist in the data\n",
    "existing_columns = [col for col in hardness_order if col in heatmap_data.columns]\n",
    "heatmap_data = heatmap_data[existing_columns]\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(\n",
    "    heatmap_data,\n",
    "    annot=True,  # Show numbers in cells\n",
    "    fmt=\"d\",  # Format as integers\n",
    "    cmap=\"YlOrRd\",  # Yellow to Orange to Red color scheme\n",
    "    cbar_kws={\"label\": \"Count\"},\n",
    ")\n",
    "\n",
    "plt.title(\"Heatmap of Hand Hardness Group by Primary Grain Form\")\n",
    "plt.xlabel(\"Hand Hardness Group\")\n",
    "plt.ylabel(\"Primary Grain Form\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Violin Plot\n",
    "\n",
    "# Function to wrap text\n",
    "def wrap_labels(ax, width=20):\n",
    "    ticks = ax.get_xticks()\n",
    "    labels = [\n",
    "        textwrap.fill(label.get_text(), width=width) for label in ax.get_xticklabels()\n",
    "    ]\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(labels)\n",
    "\n",
    "\n",
    "# Violin Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(x=\"Primary Grain Form Name\", y=\"Hardness Group\", data=layer_info_df)\n",
    "plt.title(\"Distribution of Hand Hardness Group by Primary Grain Form\")\n",
    "plt.xlabel(\"Primary Grain Form\")\n",
    "plt.ylabel(\"Hand Hardness Group\")\n",
    "wrap_labels(plt.gca(), width=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
